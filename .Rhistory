}
sim_data <- function(N, alpha, beta, sigma2_eps, X_model = "normal"){
# Simulate True Covariates
if(X_model == "normal"){
X <- rnorm(N)
} else if(X_model == "chi-square"){
X <- ( rchisq(N, 1) - 1 / (sqrt(2)) )
}
# Simulate ME
eps <- rnorm(N, sd = sqrt(sigma2_eps))
# Define surrogate
W <- X + eps
# Linear predictor
eta <- alpha + beta*X
# Simulate Y
Y <- sapply(exp(eta), function(lambda){rpois(1, lambda)})
return(list(Y=Y, X=X, W=W))
}
SIM      <- 1:200
N      <- c(200)
SIGMA2 <- c(.5)
XDIST  <- c("normal")
METHOD <- c("True", "Naive", "CS")
alpha_hat <- 0; beta_hat <- 0
results <- data.table::CJ(SIM, N, SIGMA2, XDIST, METHOD, alpha_hat, beta_hat)
MLE <- function(Y, X){
fit <- glm(Y ~ X, family = poisson)
est <- fit$coefficients
names(est) <- c("alpha", "beta")
return(fit$coefficients)
}
RC <- function(Y, W, sigma2_eps){
mu_X  <- mean(W)
var_W <- var(W)
var_X <- var_W - sigma2_eps
Xhat <- mu_X + var_X * var_W^(-1) * (W - mu_X)
return(MLE(Y, Xhat))
}
# Corrected score for Poisson regression
cscore <- function(theta, Y, W, mu_eps, sigma2_eps){
alpha <- theta[1]
beta  <- theta[2]
m_beta <- sigma2_eps * beta^2 / 2
sum(- (Y*(alpha + beta * (W - mu_eps)) - exp(alpha + beta * W - m_beta)) )
}
CS <- function(Y, W, mu_eps, sigma2_eps, init = c(0,0)){
fit <- optim(init, fn=cscore, Y=Y, W=W, mu_eps=mu_eps, sigma2_eps=sigma2_eps)
return(fit)
}
sim_data <- function(N, alpha, beta, sigma2_eps, X_model = "normal"){
# Simulate True Covariates
if(X_model == "normal"){
X <- rnorm(N)
} else if(X_model == "chi-square"){
X <- ( rchisq(N, 1) - 1 / (sqrt(2)) )
}
# Simulate ME
eps <- rnorm(N, sd = sqrt(sigma2_eps))
# Define surrogate
W <- X + eps
# Linear predictor
eta <- alpha + beta*X
# Simulate Y
Y <- sapply(exp(eta), function(lambda){rpois(1, lambda)})
return(list(Y=Y, X=X, W=W))
}
SIM      <- 1:200
N      <- c(200)
SIGMA2 <- c(.5)
XDIST  <- c("normal")
METHOD <- c("True", "Naive", "CS")
alpha_hat <- 0; beta_hat <- 0
results <- data.table::CJ(SIM, N, SIGMA2, XDIST, METHOD, alpha_hat, beta_hat)
# alpha <- 0; beta <- 1
# n <- 100
# sigma2 <- .4
# xdist <- "normal"
# i <- 1
for(n in N){
for(sigma2 in SIGMA2){
for(xdist in XDIST){
for(i in SIM){
data <- sim_data(n, alpha, beta, sigma2, xdist)
Y <- data$Y
X <- data$X
W <- data$W
for(method in METHOD){
if(method == "True"){
est <- MLE(Y, X)
}
if(method == "Naive"){
est <- MLE(Y, W)
}
if(method == "RC"){
est <- RC(Y, W, sigma2)
}
if(method == "CS"){
init <- MLE(Y, W)
est <- CS(Y, W, 0, sigma2, init)
}
results[SIM == i &
N == n &
SIGMA2 == sigma2 &
XDIST == xdist &
METHOD == method,
`:=`(alpha_hat = est[1], beta_hat = est[2])]
}
}
}
}
}
data <- sim_data(n, alpha, beta, sigma2, xdist)
xdist
sigma2
alpha
beta
SIM      <- 1:200
N      <- c(200)
SIGMA2 <- c(.5)
XDIST  <- c("normal")
METHOD <- c("True", "Naive", "CS")
alpha_hat <- 0; beta_hat <- 0
results <- data.table::CJ(SIM, N, SIGMA2, XDIST, METHOD, alpha_hat, beta_hat)
ALPHA <- 0; BETA <- 1
# alpha <- 0; beta <- 1
# n <- 100
# sigma2 <- .4
# xdist <- "normal"
# i <- 1
for(n in N){
for(sigma2 in SIGMA2){
for(xdist in XDIST){
for(i in SIM){
data <- sim_data(n, ALPHA, BETA, sigma2, xdist)
Y <- data$Y
X <- data$X
W <- data$W
for(method in METHOD){
if(method == "True"){
est <- MLE(Y, X)
}
if(method == "Naive"){
est <- MLE(Y, W)
}
if(method == "RC"){
est <- RC(Y, W, sigma2)
}
if(method == "CS"){
init <- MLE(Y, W)
est <- CS(Y, W, 0, sigma2, init)
}
results[SIM == i &
N == n &
SIGMA2 == sigma2 &
XDIST == xdist &
METHOD == method,
`:=`(alpha_hat = est[1], beta_hat = est[2])]
}
}
}
}
}
data <- sim_data(n, ALPHA, BETA, sigma2, xdist)
Y <- data$Y
W <- data$W
Y
W
X
W <- data$W
METHOD
method
init <- MLE(Y, W)
est <- CS(Y, W, 0, sigma2, init)
est
est$par
MLE <- function(Y, X){
fit <- glm(Y ~ X, family = poisson)
est <- fit$coefficients
names(est) <- c("alpha", "beta")
return(fit$coefficients)
}
RC <- function(Y, W, sigma2_eps){
mu_X  <- mean(W)
var_W <- var(W)
var_X <- var_W - sigma2_eps
Xhat <- mu_X + var_X * var_W^(-1) * (W - mu_X)
return(MLE(Y, Xhat))
}
# Corrected score for Poisson regression
cscore <- function(theta, Y, W, mu_eps, sigma2_eps){
alpha <- theta[1]
beta  <- theta[2]
m_beta <- sigma2_eps * beta^2 / 2
sum(- (Y*(alpha + beta * (W - mu_eps)) - exp(alpha + beta * W - m_beta)) )
}
CS <- function(Y, W, mu_eps, sigma2_eps, init = c(0,0)){
fit <- optim(init, fn=cscore, Y=Y, W=W, mu_eps=mu_eps, sigma2_eps=sigma2_eps)
return(fit$par)
}
sim_data <- function(N, alpha, beta, sigma2_eps, X_model = "normal"){
# Simulate True Covariates
if(X_model == "normal"){
X <- rnorm(N)
} else if(X_model == "chi-square"){
X <- ( rchisq(N, 1) - 1 / (sqrt(2)) )
}
# Simulate ME
eps <- rnorm(N, sd = sqrt(sigma2_eps))
# Define surrogate
W <- X + eps
# Linear predictor
eta <- alpha + beta*X
# Simulate Y
Y <- sapply(exp(eta), function(lambda){rpois(1, lambda)})
return(list(Y=Y, X=X, W=W))
}
SIM      <- 1:200
N      <- c(200)
SIGMA2 <- c(.5)
XDIST  <- c("normal")
METHOD <- c("True", "Naive", "CS")
alpha_hat <- 0; beta_hat <- 0
results <- data.table::CJ(SIM, N, SIGMA2, XDIST, METHOD, alpha_hat, beta_hat)
ALPHA <- 0; BETA <- 1
# alpha <- 0; beta <- 1
# n <- 100
# sigma2 <- .4
# xdist <- "normal"
# i <- 1
for(n in N){
for(sigma2 in SIGMA2){
for(xdist in XDIST){
for(i in SIM){
data <- sim_data(n, ALPHA, BETA, sigma2, xdist)
Y <- data$Y
X <- data$X
W <- data$W
for(method in METHOD){
if(method == "True"){
est <- MLE(Y, X)
}
if(method == "Naive"){
est <- MLE(Y, W)
}
if(method == "RC"){
est <- RC(Y, W, sigma2)
}
if(method == "CS"){
init <- MLE(Y, W)
est <- CS(Y, W, 0, sigma2, init)
}
results[SIM == i &
N == n &
SIGMA2 == sigma2 &
XDIST == xdist &
METHOD == method,
`:=`(alpha_hat = est[1], beta_hat = est[2])]
}
}
}
}
}
# fwrite(results, "HW4_simulation_results.csv")
results
results
MLE <- function(Y, X){
fit <- glm(Y ~ X, family = poisson)
est <- fit$coefficients
names(est) <- c("alpha", "beta")
return(fit$coefficients)
}
RC <- function(Y, W, sigma2_eps){
mu_X  <- mean(W)
var_W <- var(W)
var_X <- var_W - sigma2_eps
Xhat <- mu_X + var_X * var_W^(-1) * (W - mu_X)
return(MLE(Y, Xhat))
}
# Corrected score for Poisson regression
cscore <- function(theta, Y, W, mu_eps, sigma2_eps){
alpha <- theta[1]
beta  <- theta[2]
m_beta <- sigma2_eps * beta^2 / 2
sum(- (Y*(alpha + beta * (W - mu_eps)) - exp(alpha + beta * W - m_beta)) )
}
CS <- function(Y, W, mu_eps, sigma2_eps, init = c(0,0)){
fit <- optim(init, fn=cscore, Y=Y, W=W, mu_eps=mu_eps, sigma2_eps=sigma2_eps)
return(fit$par)
}
sim_data <- function(N, alpha, beta, sigma2_eps, X_model = "normal"){
# Simulate True Covariates
if(X_model == "normal"){
X <- rnorm(N)
} else if(X_model == "chi-square"){
X <- ( rchisq(N, 1) - 1 / (sqrt(2)) )
}
# Simulate ME
eps <- rnorm(N, sd = sqrt(sigma2_eps))
# Define surrogate
W <- X + eps
# Linear predictor
eta <- alpha + beta*X
# Simulate Y
Y <- sapply(exp(eta), function(lambda){rpois(1, lambda)})
return(list(Y=Y, X=X, W=W))
}
set.seed(123)
SIM      <- 1:200
N      <- c(200)
SIGMA2 <- c(.5)
XDIST  <- c("normal")
METHOD <- c("True", "Naive", "CS")
alpha_hat <- 0; beta_hat <- 0
results <- data.table::CJ(SIM, N, SIGMA2, XDIST, METHOD, alpha_hat, beta_hat)
ALPHA <- 0; BETA <- 1
# alpha <- 0; beta <- 1
# n <- 100
# sigma2 <- .4
# xdist <- "normal"
# i <- 1
for(n in N){
for(sigma2 in SIGMA2){
for(xdist in XDIST){
for(i in SIM){
data <- sim_data(n, ALPHA, BETA, sigma2, xdist)
Y <- data$Y
X <- data$X
W <- data$W
for(method in METHOD){
if(method == "True"){
est <- MLE(Y, X)
}
if(method == "Naive"){
est <- MLE(Y, W)
}
if(method == "RC"){
est <- RC(Y, W, sigma2)
}
if(method == "CS"){
init <- MLE(Y, W)
est <- CS(Y, W, 0, sigma2, init)
}
results[SIM == i &
N == n &
SIGMA2 == sigma2 &
XDIST == xdist &
METHOD == method,
`:=`(alpha_hat = est[1], beta_hat = est[2])]
}
}
}
}
}
fwrite(results, "HW5_simulation_results.csv")
results <- fread("HW5_simulation_results.csv")
summary <- melt(results, id.vars = c("N", "SIGMA2", "XDIST", "METHOD"),
measure.vars=c("alpha_hat", "beta_hat"),
variable.name = "parameter", value.name = "est")
final <- summary[, .(mean = mean(est),
se = var(est)^.5), .(N, SIGMA2, XDIST, METHOD, parameter)]
final[, `:=`(lower = mean - 1.96*se, upper = mean+1.96*se)]
final[, truth := ifelse(parameter == "alpha_hat", 0, 1)]
final[, SIGMA2 := as.factor(SIGMA2)]
final[, N := as.factor(N)]
alpha_table <- results[, .(bias = mean(alpha_hat), sd = sd(alpha_hat)), .(N, SIGMA2, METHOD)]
beta_table <- results[, .(bias = mean(beta_hat - 1), sd = sd(beta_hat)), .(N, SIGMA2, METHOD)]
final
summary
summary[METHOD == "CS"]
View(summary[METHOD == "CS"])
summary
summary[METHOD == "CS" & parameter == "alpha_hat",]
summary[METHOD == "CS" & parameter == "alpha_hat",]
summary[METHOD == "CS" & parameter == "alpha_hat" & est > 10, ]
summary[METHOD == "CS" & parameter == "alpha_hat" & est > 5, ]
summary[METHOD == "CS" & parameter == "alpha_hat" & est > 2, ]
summary[METHOD == "CS" & parameter == "alpha_hat" & est > 1, ]
summary[METHOD == "CS" & parameter == "alpha_hat" & est > .5, ]
summary[METHOD == "CS" & parameter == "alpha_hat" & est > .2, ]
summary[METHOD == "CS" & parameter == "beta_hat" & est > 2, ]
summary[METHOD == "CS" & parameter == "beta_hat" & est > 1.5, ]
summary[METHOD == "CS" & parameter == "beta_hat" & est > 2, ]
summary[METHOD == "CS" & est > 2, ]
summary[est > 2, ]
summary <- summary[est < 2]
results <- fread("HW5_simulation_results.csv")
summary <- melt(results, id.vars = c("N", "SIGMA2", "XDIST", "METHOD"),
measure.vars=c("alpha_hat", "beta_hat"),
variable.name = "parameter", value.name = "est")
summary <- summary[est < 2]
final <- summary[, .(mean = mean(est),
se = var(est)^.5), .(N, SIGMA2, XDIST, METHOD, parameter)]
final[, `:=`(lower = mean - 1.96*se, upper = mean+1.96*se)]
final[, truth := ifelse(parameter == "alpha_hat", 0, 1)]
final[, SIGMA2 := as.factor(SIGMA2)]
final[, N := as.factor(N)]
alpha_table <- results[, .(bias = mean(alpha_hat), sd = sd(alpha_hat)), .(N, SIGMA2, METHOD)]
beta_table <- results[, .(bias = mean(beta_hat - 1), sd = sd(beta_hat)), .(N, SIGMA2, METHOD)]
final
results <- fread("HW5_simulation_results.csv")
summary <- melt(results, id.vars = c("N", "SIGMA2", "XDIST", "METHOD"),
measure.vars=c("alpha_hat", "beta_hat"),
variable.name = "parameter", value.name = "est")
summary <- summary[est < 2]
final <- summary[, .(mean = mean(est),
se = var(est)^.5), .(N, SIGMA2, XDIST, METHOD, parameter)]
final[, `:=`(lower = mean - 1.96*se, upper = mean+1.96*se)]
final[, truth := ifelse(parameter == "alpha_hat", 0, 1)]
final[, SIGMA2 := as.factor(SIGMA2)]
final[, N := as.factor(N)]
alpha_table <- results[, .(bias = mean(alpha_hat), sd = sd(alpha_hat)), .(N, SIGMA2, METHOD)]
beta_table <- results[, .(bias = mean(beta_hat - 1), sd = sd(beta_hat)), .(N, SIGMA2, METHOD)]
final
summary
summary[METHOD == "CS" & parameter == "alpha_hat"]
summary[METHOD == "CS" & parameter == "alpha_hat", est]
summary[abs(est) < 2]
summary[abs(est) > 2]
results <- fread("HW5_simulation_results.csv")
summary <- melt(results, id.vars = c("N", "SIGMA2", "XDIST", "METHOD"),
measure.vars=c("alpha_hat", "beta_hat"),
variable.name = "parameter", value.name = "est")
summary <- summary[abs(est) < 2]
final <- summary[, .(mean = mean(est),
se = var(est)^.5), .(N, SIGMA2, XDIST, METHOD, parameter)]
final[, `:=`(lower = mean - 1.96*se, upper = mean+1.96*se)]
final[, truth := ifelse(parameter == "alpha_hat", 0, 1)]
final[, SIGMA2 := as.factor(SIGMA2)]
final[, N := as.factor(N)]
alpha_table <- results[, .(bias = mean(alpha_hat), sd = sd(alpha_hat)), .(N, SIGMA2, METHOD)]
beta_table <- results[, .(bias = mean(beta_hat - 1), sd = sd(beta_hat)), .(N, SIGMA2, METHOD)]
ggplot(final[N==200], aes(METHOD, mean, col=SIGMA2)) +
geom_point(alpha=0.6, size=3) +
geom_errorbar(aes(ymin=lower, ymax=upper), alpha=0.6, size=0.5) +
facet_grid( XDIST ~ parameter, scales = "free") +
geom_hline(aes(yintercept=truth), linetype = "dashed", col="red") +
theme_bw() +
ggtitle("Simulation Results for N=300")
ggplot(final[N==200], aes(METHOD, mean)) +
geom_point(alpha=0.6, size=3) +
geom_errorbar(aes(ymin=lower, ymax=upper), alpha=0.6, size=0.5) +
facet_grid( XDIST ~ parameter, scales = "free") +
geom_hline(aes(yintercept=truth), linetype = "dashed", col="red") +
theme_bw() +
ggtitle("Simulation Results for N=300")
ggplot(final[N==200], aes(METHOD, mean)) +
geom_point(alpha=0.6, size=3) +
geom_errorbar(aes(ymin=lower, ymax=upper), alpha=0.6, size=0.5) +
facet_grid( XDIST ~ parameter, scales = "free") +
geom_hline(aes(yintercept=truth), linetype = "dashed", col="red") +
theme_bw() +
ggtitle("Simulation Results for N=200")
final
results
results[abs(alpha_hat) > 2 | abs(beta_hat) > 2]
results[abs(alpha_hat) > 3 | abs(beta_hat) > 3]
results <- fread("HW5_simulation_results.csv")
summary <- melt(results, id.vars = c("N", "SIGMA2", "XDIST", "METHOD"),
measure.vars=c("alpha_hat", "beta_hat"),
variable.name = "parameter", value.name = "est")
summary[abs(est) > 2]
results <- fread("HW5_simulation_results.csv")
summary <- melt(results, id.vars = c("N", "SIGMA2", "XDIST", "METHOD"),
measure.vars=c("alpha_hat", "beta_hat"),
variable.name = "parameter", value.name = "est")
summary <- summary[abs(est) < 2]
final <- summary[, .(mean = mean(est),
se = var(est)^.5), .(N, SIGMA2, XDIST, METHOD, parameter)]
final[, `:=`(lower = mean - 1.96*se, upper = mean+1.96*se)]
final[, truth := ifelse(parameter == "alpha_hat", 0, 1)]
final[, SIGMA2 := as.factor(SIGMA2)]
final[, N := as.factor(N)]
alpha_table <- results[, .(bias = mean(alpha_hat), sd = sd(alpha_hat)), .(N, SIGMA2, METHOD)]
beta_table <- results[, .(bias = mean(beta_hat - 1), sd = sd(beta_hat)), .(N, SIGMA2, METHOD)]
ggplot(final[N==200], aes(METHOD, mean)) +
geom_point(alpha=0.6, size=3) +
geom_errorbar(aes(ymin=lower, ymax=upper), alpha=0.6, size=0.5) +
facet_grid( XDIST ~ parameter, scales = "free") +
geom_hline(aes(yintercept=truth), linetype = "dashed", col="red") +
theme_bw() +
ggtitle("Simulation Results for N=200")
results
results[abs(alpha_hat) > 2]
discard_sim <-results[abs(alpha_hat) > 2, SIM]
discard_sim
results <- results[!(SIM %in% discard_sim)]
results
summary <- melt(results, id.vars = c("N", "SIGMA2", "XDIST", "METHOD"),
measure.vars=c("alpha_hat", "beta_hat"),
variable.name = "parameter", value.name = "est")
results <- fread("HW5_simulation_results.csv")
discard_sim <-results[abs(alpha_hat) > 2, SIM]
results <- results[!(SIM %in% discard_sim)]
summary <- melt(results, id.vars = c("N", "SIGMA2", "XDIST", "METHOD"),
measure.vars=c("alpha_hat", "beta_hat"),
variable.name = "parameter", value.name = "est")
final <- summary[, .(mean = mean(est),
se = var(est)^.5), .(N, SIGMA2, XDIST, METHOD, parameter)]
final[, `:=`(lower = mean - 1.96*se, upper = mean+1.96*se)]
final[, truth := ifelse(parameter == "alpha_hat", 0, 1)]
final[, SIGMA2 := as.factor(SIGMA2)]
final[, N := as.factor(N)]
alpha_table <- results[, .(bias = mean(alpha_hat), sd = sd(alpha_hat)), .(N, SIGMA2, METHOD)]
beta_table <- results[, .(bias = mean(beta_hat - 1), sd = sd(beta_hat)), .(N, SIGMA2, METHOD)]
ggplot(final[N==200], aes(METHOD, mean)) +
geom_point(alpha=0.6, size=3) +
geom_errorbar(aes(ymin=lower, ymax=upper), alpha=0.6, size=0.5) +
facet_grid( XDIST ~ parameter, scales = "free") +
geom_hline(aes(yintercept=truth), linetype = "dashed", col="red") +
theme_bw() +
ggtitle("Simulation Results for N=200")
knitr::kable(dcast(beta_table, N + SIGMA2 ~ METHOD, value.var = c("bias")), digits=5, caption = "Bias for beta for conditional score")
